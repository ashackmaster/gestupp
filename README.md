# ğŸŒŒ Gesture-Controlled 3D Model Viewer 

A modern and interactive application that allows users to control 3D models using **hand gestures**.  
This project demonstrates a fully interactive **3D Solar System** where planets and objects can be explored using natural hand movementsâ€”without a mouse or keyboard.

---

## ğŸš€ Key Highlights

- âœ‹ **Real-Time Hand Gesture Control** using MediaPipe  
- ğŸŒ **Interactive 3D Solar System** with smooth animations  
- ğŸ§  **Gesture-to-Action Mapping** for intuitive 3D navigation  
- ğŸ¨ **Modern, Responsive UI** built with Tailwind CSS  
- âš¡ Optimized for performance and low-latency interaction

---

## ğŸš€ Features

- âœ‹ **Real-Time Hand Gesture Control**  
  Control 3D models using natural hand movements.

- ğŸŒ€ **Multiple Gesture Support**
  - Rotate objects
  - Zoom In / Zoom Out
  - Pan / Move in 3D space
  - Reset camera view

- â˜€ï¸ **3D Solar System Model**
  - Sun and all major planets
  - Smooth animations
  - Realistic 3D visualization

- âš¡ **Smooth & Responsive Interaction**
  - Low-latency gesture detection
  - Fluid and immersive 3D experience

---

## ğŸ§  How It Works

The application uses a gesture recognition system to detect hand movements in real time.  
Each gesture is mapped to specific 3D transformations such as rotation, zoom, and translation, allowing intuitive control over the Solar System model.

---

## ğŸ› ï¸ Tech Stack

- **Frontend:** React, TypeScript  
- **3D Rendering:** Three.js, Google 3D Model Viewer  
- **Gesture Recognition:** MediaPipe  
- **Styling:** Tailwind CSS  
- **Architecture:** Component-based, modular design  

---

## ğŸ¯ What This Project Demonstrates

- Advanced frontend development with React and TypeScript  
- Real-time computer vision integration in web applications  
- 3D graphics rendering and interaction design  
- Clean code structure and scalable architecture  
- Strong focus on modern UI/UX principles  

---

## ğŸ® Use Cases

- Educational visualization of the Solar System  
- Interactive science demonstrations  
- Gesture-based humanâ€“computer interaction experiments  
- Portfolio and showcase projects

---

## ğŸ‘¨â€ğŸ’» Live Preview

https://gestupp.vercel.app

---

## ğŸ“Œ Future Enhancements

- Custom gesture mapping
- Planet information overlay (distance, speed, facts)
- Multi-hand interaction support
- VR / AR integration
- Gesture customization and sensitivity control  
- Informational overlays for each planet  

---

## ğŸ“„ License

This project is open-source and intended for educational and experimental purposes.
